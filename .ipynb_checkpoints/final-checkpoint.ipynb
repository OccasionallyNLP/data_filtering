{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68cdfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [i for i in os.listdir('/home/work/user/wjpark/midm_pack/data/')]\n",
    "data_list_ = []\n",
    "for i in data_list:\n",
    "    for j in list(map(str, range(2013, 2024))):\n",
    "        if j in i:\n",
    "            if 'test' not in i:\n",
    "                \n",
    "                data_list_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4ef2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-23 2021-17 2020-40 2021-04 2016-26 2015-22 2017-09 2018-05 2018-43 2017-43 2021-21 2023-06 2021-31 2019-39 2015-35 2019-13 2017-51 2016-36 2019-47 2020-10 2017-17 2019-43 2017-04 2022-21 2018-34 2018-22 2021-39 2014-10 2022-27 2015-48 2018-09 2022-40 2016-18 2019-51 2018-51 2021-43 2013-20 2013-48 2019-09 2017-47 2017-26 2018-17 2016-22 2016-40 2021-49 2019-22 2019-18 2019-30 2018-47 2016-07 2018-30 2017-22 2023-14 2017-30 2023-23 2020-50 2017-34 2018-26 2014-49 2020-45 2022-05 2018-39 2020-29 2023-40 2020-16 2014-35 2019-35 2015-32 2019-26 2014-15 2018-13 2022-33 2016-44 2017-39 2020-05 2016-30 2021-25 2021-10 2020-34 2020-24 2016-50 2023-50 2019-04'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f77d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c79e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path, verbose=False):\n",
    "    result = []\n",
    "    f = open(path,'r',encoding = 'utf-8')\n",
    "    len(f)\n",
    "    for i in tqdm(f, disable=not verbose):\n",
    "        try:\n",
    "            result.append(json.loads(i))\n",
    "        except:\n",
    "            continue\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d73535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 1/80 [03:54<5:08:21, 234.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 130 -------> after : 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 2/80 [04:09<2:17:08, 105.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 12 -------> after : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 3/80 [04:26<1:23:30, 65.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 14 -------> after : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 4/80 [05:48<1:30:46, 71.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 56 -------> after : 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 5/80 [08:29<2:09:55, 103.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 118 -------> after : 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% 6/80 [12:38<3:08:53, 153.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 162 -------> after : 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% 7/80 [15:22<3:10:48, 156.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 108 -------> after : 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 8/80 [17:12<2:50:21, 141.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 70 -------> after : 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% 9/80 [21:36<3:33:11, 180.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 176 -------> after : 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% 10/80 [25:06<3:40:53, 189.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 144 -------> after : 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 11/80 [28:30<3:42:56, 193.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 146 -------> after : 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15% 12/80 [28:42<2:37:00, 138.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 12 -------> after : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 13/80 [31:47<2:50:17, 152.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 132 -------> after : 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 14/80 [33:28<2:30:30, 136.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 68 -------> after : 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19% 15/80 [33:52<1:51:23, 102.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 16 -------> after : 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 16/80 [37:00<2:17:09, 128.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 134 -------> after : 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21% 17/80 [41:15<2:55:00, 166.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 192 -------> after : 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 18/80 [43:19<2:38:57, 153.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 82 -------> after : 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 19/80 [47:50<3:12:04, 188.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 200 -------> after : 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% 20/80 [49:06<2:35:09, 155.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 52 -------> after : 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 21/80 [53:13<2:59:28, 182.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 172 -------> after : 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 22/80 [56:14<2:56:01, 182.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 128 -------> after : 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29% 23/80 [57:04<2:15:29, 142.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 34 -------> after : 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 24/80 [1:00:27<2:29:47, 160.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 134 -------> after : 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31% 25/80 [1:00:34<1:45:08, 114.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 8 -------> after : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 26/80 [1:04:50<2:21:13, 156.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 170 -------> after : 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 27/80 [1:04:58<1:39:14, 112.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 8 -------> after : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35% 28/80 [1:07:40<1:50:16, 127.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 116 -------> after : 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 29/80 [1:11:52<2:20:02, 164.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 172 -------> after : 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 30/80 [1:12:09<1:40:08, 120.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 10 -------> after : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39% 31/80 [1:16:23<2:11:07, 160.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 180 -------> after : 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 32/80 [1:19:28<2:14:08, 167.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 130 -------> after : 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41% 33/80 [1:23:31<2:29:03, 190.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 158 -------> after : 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 34/80 [1:23:31<1:42:12, 133.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 2 -------> after : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% 35/80 [1:23:36<1:10:59, 94.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 4 -------> after : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45% 36/80 [1:24:58<1:06:41, 90.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 54 -------> after : 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% 37/80 [1:27:33<1:18:57, 110.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 110 -------> after : 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% 38/80 [1:29:55<1:23:45, 119.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 94 -------> after : 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% 39/80 [1:31:30<1:16:51, 112.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 68 -------> after : 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 40/80 [1:31:55<57:30, 86.27s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 18 -------> after : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51% 41/80 [1:32:24<44:49, 68.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 20 -------> after : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% 42/80 [1:34:29<54:18, 85.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 80 -------> after : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 43/80 [1:37:38<1:11:56, 116.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 138 -------> after : 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55% 44/80 [1:40:21<1:18:17, 130.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 116 -------> after : 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 45/80 [1:43:48<1:29:38, 153.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 148 -------> after : 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 46/80 [1:46:59<1:33:25, 164.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 114 -------> after : 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59% 47/80 [1:47:28<1:08:11, 124.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 22 -------> after : 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 48/80 [1:50:25<1:14:41, 140.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 128 -------> after : 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61% 49/80 [1:52:35<1:10:46, 136.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 84 -------> after : 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% 50/80 [1:56:46<1:25:31, 171.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 170 -------> after : 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 51/80 [1:58:38<1:14:07, 153.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 74 -------> after : 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65% 52/80 [2:02:57<1:26:18, 184.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 178 -------> after : 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% 53/80 [2:06:55<1:30:31, 201.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 164 -------> after : 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68% 54/80 [2:09:12<1:18:47, 181.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 92 -------> after : 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69% 55/80 [2:12:18<1:16:13, 182.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 120 -------> after : 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 56/80 [2:12:27<52:20, 130.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 10 -------> after : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71% 57/80 [2:15:08<53:38, 139.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 102 -------> after : 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72% 58/80 [2:19:38<1:05:37, 179.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 166 -------> after : 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% 59/80 [2:23:32<1:08:21, 195.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 148 -------> after : 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75% 60/80 [2:29:27<1:21:04, 243.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 222 -------> after : 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% 61/80 [2:34:23<1:22:01, 259.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 188 -------> after : 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78% 62/80 [2:38:55<1:18:52, 262.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 190 -------> after : 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79% 63/80 [2:39:06<53:04, 187.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 12 -------> after : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 64/80 [2:43:43<57:09, 214.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 182 -------> after : 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% 65/80 [2:43:58<38:36, 154.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 12 -------> after : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82% 66/80 [2:47:37<40:32, 173.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 150 -------> after : 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84% 67/80 [2:47:44<26:50, 123.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 10 -------> after : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85% 68/80 [2:50:34<27:31, 137.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 116 -------> after : 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% 69/80 [2:54:01<29:03, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 134 -------> after : 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88% 70/80 [2:55:13<22:05, 132.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 56 -------> after : 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89% 71/80 [2:56:21<17:00, 113.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 42 -------> after : 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 72/80 [3:01:35<23:08, 173.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 216 -------> after : 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91% 73/80 [3:02:18<15:39, 134.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 26 -------> after : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% 74/80 [3:05:50<15:44, 157.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 134 -------> after : 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94% 75/80 [3:09:34<14:47, 177.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 142 -------> after : 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95% 76/80 [3:12:27<11:44, 176.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 112 -------> after : 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% 77/80 [3:17:39<10:50, 216.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 216 -------> after : 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% 78/80 [3:19:12<05:59, 179.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 68 -------> after : 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% 79/80 [3:24:17<03:37, 217.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 204 -------> after : 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 80/80 [3:28:17<00:00, 156.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 156 -------> after : 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name in tqdm(data_list_[3:]):\n",
    "    path = f'/home/work/user/wjpark/midm_pack/data/{name}/remove_duplicate'\n",
    "    before = os.listdir(path)\n",
    "    for i in os.listdir(path):\n",
    "        if i.endswith('part'):\n",
    "            data = load_jsonl(os.path.join(path,i), False)\n",
    "            if len(data)<=1:\n",
    "                os.remove(os.path.join(path,i))\n",
    "        else:\n",
    "            os.remove(os.path.join(path,i))\n",
    "    after = os.listdir(path)\n",
    "    print(f'before : {len(before)} -------> after : {len(after)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad04250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/work/user/ocw/data_filtering_'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './upload/test.txt'\n",
    "\n",
    "if os.path.isfile(file):\n",
    "  os.remove(file)\n",
    "\n",
    "  return 'okay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa6b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "tokenizer = Kiwi(model_type='sbg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b588ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(text):\n",
    "    tokens = [token.form for token in tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c6842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 7416/27583 [08:43<19:55, 16.87it/s]  "
     ]
    }
   ],
   "source": [
    "for i in tqdm(data):\n",
    "    word_tokenize(i['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00dd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37aeb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatrove.pipeline.filters import (\n",
    "    C4QualityFilter,\n",
    "    FineWebQualityFilter,\n",
    "    GopherQualityFilter,\n",
    "    GopherRepetitionFilter,\n",
    "    LanguageFilter,\n",
    "    URLFilter,\n",
    ")\n",
    "\n",
    "from typing import Callable, Literal\n",
    "from datatrove.io import DataFileLike, DataFolderLike\n",
    "from datatrove.pipeline.readers.base import BaseDiskReader\n",
    "from datatrove.utils.logging import logger\n",
    "\n",
    "\n",
    "class JsonlReader(BaseDiskReader):\n",
    "    \"\"\"Read data from JSONL files.\n",
    "        Will read each line as a separate document.\n",
    "\n",
    "    Args:\n",
    "        data_folder: a str, tuple or DataFolder object representing a path/filesystem\n",
    "        paths_file: optionally provide a file with one path per line (without the `data_folder` prefix) to read.\n",
    "        compression: the compression to use (default: \"infer\")\n",
    "        limit: limit the number of documents to read. Useful for debugging\n",
    "        skip: skip the first n rows\n",
    "        file_progress: show progress bar for files\n",
    "        doc_progress: show progress bar for documents\n",
    "        adapter: function to adapt the data dict from the source to a Document.\n",
    "            Takes as input: (self, data: dict, path: str, id_in_file: int | str)\n",
    "                self allows access to self.text_key and self.id_key\n",
    "            Returns: a dict with at least a \"text\" and \"id\" keys\n",
    "        text_key: the key containing the text data (default: \"text\").\n",
    "        id_key: the key containing the id for each sample (default: \"id\").\n",
    "        default_metadata: a dictionary with any data that should be added to all samples' metadata\n",
    "        recursive: whether to search files recursively. Ignored if paths_file is provided\n",
    "        glob_pattern: pattern that all files must match exactly to be included (relative to data_folder). Ignored if paths_file is provided\n",
    "        shuffle_files: shuffle the files within the returned shard. Mostly used for data viz. purposes, do not use with dedup blocks\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"🐿 Jsonl\"\n",
    "    _requires_dependencies = [\"orjson\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_folder: DataFolderLike,\n",
    "        paths_file: DataFileLike | None = None,\n",
    "        compression: Literal[\"infer\", \"gzip\", \"zstd\"] | None = \"infer\",\n",
    "        limit: int = -1,\n",
    "        skip: int = 0,\n",
    "        file_progress: bool = False,\n",
    "        doc_progress: bool = False,\n",
    "        adapter: Callable = None,\n",
    "        text_key: str = \"text\",\n",
    "        id_key: str = \"id\",\n",
    "        default_metadata: dict = None,\n",
    "        recursive: bool = True,\n",
    "        glob_pattern: str | None = None,\n",
    "        shuffle_files: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            data_folder,\n",
    "            paths_file,\n",
    "            limit,\n",
    "            skip,\n",
    "            file_progress,\n",
    "            doc_progress,\n",
    "            adapter,\n",
    "            text_key,\n",
    "            id_key,\n",
    "            default_metadata,\n",
    "            recursive,\n",
    "            glob_pattern,\n",
    "            shuffle_files,\n",
    "        )\n",
    "        self.compression = compression\n",
    "\n",
    "    def read_file(self, filepath: str):\n",
    "        import orjson\n",
    "        from orjson import JSONDecodeError\n",
    "\n",
    "        with self.data_folder.open(filepath, \"r\", compression=self.compression) as f:\n",
    "            try:\n",
    "                for li, line in enumerate(f):\n",
    "                    with self.track_time():\n",
    "                        try:\n",
    "                            document = self.get_document_from_dict(orjson.loads(line), filepath, li)\n",
    "                            document.text=document.text.replace('<[!newline]>\\n','\\n')\n",
    "                            if not document:\n",
    "                                continue\n",
    "                        except (EOFError, JSONDecodeError) as e:\n",
    "                            logger.warning(f\"Error when reading `{filepath}`: {e}\")\n",
    "                            continue\n",
    "                    yield document\n",
    "            except UnicodeDecodeError as e:\n",
    "                logger.warning(f\"File `{filepath}` may be corrupted: raised UnicodeDecodeError ({e})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc1e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [os.path.join(path,i) for i in os.listdir(path) if i.endswith('part')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatrove.data import Document\n",
    "import datatrove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09fbb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(filter_for_fineweb, dataset:datatrove.data.Document):\n",
    "    after = []\n",
    "    filtered = []\n",
    "    whys = []\n",
    "    for i in tqdm(dataset):\n",
    "        if filter_for_fineweb.filter(i)==True:\n",
    "            after.append(i)\n",
    "        else:\n",
    "            why = str(filter_for_fineweb.filter(i))\n",
    "            whys.append(why)\n",
    "            filtered.append(i)\n",
    "    print(f'size of dataset before filtering - {len(dataset)}')\n",
    "    print(f'size of dataset after filtering - {len(after)}')\n",
    "    return after, filtered, whys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20189a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9455it [00:00, 38978.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_name in data_list[:1]:\n",
    "    data = load_jsonl(data_name)\n",
    "    for i in data:\n",
    "        i['text']=i['text'].replace('<[!newline]>\\n','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de27a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/user/wjpark/midm_pack/data/2021-17/remove_duplicate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:49:37.505 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=8\n",
      "2024-08-12 07:49:37.505 | INFO     | datatrove.utils.logging:log_pipeline:90 - \n",
      "--- 🛠️ PIPELINE 🛠\n",
      "📖 - READER: 🐿 Jsonl\n",
      "🔻 - FILTER: 😈 Url-filter\n",
      "🔻 - FILTER: 👯 Gopher Repetition\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "2024-08-12 07:49:37.543 | INFO     | datatrove.pipeline.readers.base:read_files_shard:191 - Reading input file 105.jsonl.part, 1/1\n",
      "2024-08-12 07:49:52.951 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 1/110 tasks completed.\n",
      "2024-08-12 07:49:52.954 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 2/110 tasks completed.\n",
      "Process ForkServerPoolWorker-19:\n",
      "2024-08-12 07:49:52.958 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 3/110 tasks completed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "Process ForkServerPoolWorker-24:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_repetition_filter.py\", line 127, in filter\n",
      "    words = self.tokenizer.word_tokenize(text)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py\", line 206, in word_tokenize\n",
      "    tokens = [token.form for token in self.tokenizer.tokenize(text)]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1278, in tokenize\n",
      "    return self._tokenize(text, match_options, normalize_coda, z_coda, split_complex, split_sents, stopwords, echo,\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1096, in _tokenize\n",
      "    return _refine_result(super().analyze(text, 1, match_options, False, blocklist, pretokenized))\n",
      "KeyboardInterrupt\n",
      "2024-08-12 07:49:52.959 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 4/110 tasks completed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_repetition_filter.py\", line 127, in filter\n",
      "    words = self.tokenizer.word_tokenize(text)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py\", line 206, in word_tokenize\n",
      "    tokens = [token.form for token in self.tokenizer.tokenize(text)]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1278, in tokenize\n",
      "    return self._tokenize(text, match_options, normalize_coda, z_coda, split_complex, split_sents, stopwords, echo,\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1096, in _tokenize\n",
      "    return _refine_result(super().analyze(text, 1, match_options, False, blocklist, pretokenized))\n",
      "KeyboardInterrupt\n",
      "Process ForkServerPoolWorker-23:\n",
      "Process ForkServerPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_repetition_filter.py\", line 127, in filter\n",
      "    words = self.tokenizer.word_tokenize(text)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py\", line 206, in word_tokenize\n",
      "    tokens = [token.form for token in self.tokenizer.tokenize(text)]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1278, in tokenize\n",
      "    return self._tokenize(text, match_options, normalize_coda, z_coda, split_complex, split_sents, stopwords, echo,\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1096, in _tokenize\n",
      "    return _refine_result(super().analyze(text, 1, match_options, False, blocklist, pretokenized))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 64, in run\n",
      "    for batch in batched(data, self.batch_size):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/batching.py\", line 20, in batched\n",
      "    while batch := list(itertools.islice(it, n)):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/url_filter.py\", line 111, in filter\n",
      "    url_info = self.tldextractor(url)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/tldextract/tldextract.py\", line 227, in __call__\n",
      "    return self.extract_str(url, include_psl_private_domains, session=session)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/tldextract/tldextract.py\", line 256, in extract_str\n",
      "    return self._extract_netloc(\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/tldextract/tldextract.py\", line 307, in _extract_netloc\n",
      "    suffix_index, is_private = self._get_tld_extractor(\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/tldextract/tldextract.py\", line 494, in suffix_index\n",
      "    if decoded_label in node.matches:\n",
      "KeyboardInterrupt\n",
      "2024-08-12 07:49:52.967 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 5/110 tasks completed.\n",
      "2024-08-12 07:49:52.969 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 6/110 tasks completed.\n",
      "Process ForkServerPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_repetition_filter.py\", line 127, in filter\n",
      "    words = self.tokenizer.word_tokenize(text)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py\", line 206, in word_tokenize\n",
      "    tokens = [token.form for token in self.tokenizer.tokenize(text)]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1278, in tokenize\n",
      "    return self._tokenize(text, match_options, normalize_coda, z_coda, split_complex, split_sents, stopwords, echo,\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1096, in _tokenize\n",
      "    return _refine_result(super().analyze(text, 1, match_options, False, blocklist, pretokenized))\n",
      "KeyboardInterrupt\n",
      "Process ForkServerPoolWorker-22:\n",
      "2024-08-12 07:49:52.976 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 7/110 tasks completed.\n",
      "2024-08-12 07:49:52.979 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 8/110 tasks completed.\n",
      "Process ForkServerPoolWorker-32:\n",
      "2024-08-12 07:49:52.985 | INFO     | datatrove.executor.local:_launch_run_for_rank:81 - 9/110 tasks completed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/local.py\", line 76, in _launch_run_for_rank\n",
      "    return self._run_for_rank(rank, local_rank)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/executor/base.py\", line 96, in _run_for_rank\n",
      "    deque(pipelined_data, maxlen=0)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py\", line 176, in run\n",
      "    for document in data:\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 68, in run\n",
      "    batch_filter_result = self.filter_batch(batch)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py\", line 60, in filter_batch\n",
      "    return list(map(self.filter, batch))\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_repetition_filter.py\", line 127, in filter\n",
      "    words = self.tokenizer.word_tokenize(text)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py\", line 206, in word_tokenize\n",
      "    tokens = [token.form for token in self.tokenizer.tokenize(text)]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1278, in tokenize\n",
      "    return self._tokenize(text, match_options, normalize_coda, z_coda, split_complex, split_sents, stopwords, echo,\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/kiwipiepy/_wrap.py\", line 1096, in _tokenize\n",
      "    return _refine_result(super().analyze(text, 1, match_options, False, blocklist, pretokenized))\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    URLFilter(),\n",
    "    GopherRepetitionFilter(language='ko'),\n",
    "    GopherQualityFilter(min_stop_words=None,language='ko'),\n",
    "    C4QualityFilter(filter_no_terminal_punct=False,language='ko')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
